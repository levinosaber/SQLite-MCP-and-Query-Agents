#!/usr/bin/env python3
"""
åƒåœ¾ç›‘ç®¡ç³»ç»ŸAIæ™ºèƒ½ä½“
åŸºäºLangGraphå®˜æ–¹MCPé€‚é…å™¨å®ç°æ™ºèƒ½æŸ¥è¯¢å·¥ä½œæµ
"""
import os
import json
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, TypedDict, Annotated
import asyncio

# LangGraphå’ŒLangChainç›¸å…³å¯¼å…¥
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

# MCPé€‚é…å™¨å¯¼å…¥
from langchain_mcp_adapters.client import MultiServerMCPClient

# === VS Code è°ƒè¯•æ¡¥ ===
# import debugpy
# debugpy.listen(("0.0.0.0", 5678))    # ç«¯å£éšæ„
# print("Waiting for debugger attach on 5678...")
# debugpy.wait_for_client()            # å…ˆæŒ‚èµ·ï¼Œè¿ä¸Šåæ‰ç»§ç»­
# =======================

# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class AgentResponse(BaseModel):
    """Agentçš„ç»“æ„åŒ–å“åº”"""
    if_continue: bool = Field(description="æ˜¯å¦éœ€è¦ç”¨æˆ·ç»§ç»­æä¾›ä¿¡æ¯")
    returned_content: str = Field(description="è¿”å›çš„å†…å®¹ï¼Œå¦‚æœif_continueä¸ºTrueåˆ™ä¸ºç©º")


def get_project_root():
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    # ä»å½“å‰è„šæœ¬æ–‡ä»¶çš„ä½ç½®å¼€å§‹æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•
    current_path = Path(__file__).parent
    
    # å¦‚æœå½“å‰åœ¨agentsç›®å½•ï¼Œåˆ™å‘ä¸Šä¸€çº§
    if current_path.name == "agents":
        return current_path.parent
    
    # å¦åˆ™æŸ¥æ‰¾åŒ…å«æ ‡è¯†æ–‡ä»¶çš„ç›®å½•
    markers = ['pyproject.toml', 'setup.py', 'requirements.txt', '.git']
    while current_path != current_path.parent:
        for marker in markers:
            if (current_path / marker).exists():
                return current_path
        current_path = current_path.parent
    
    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•
    return Path(__file__).parent.parent

PROJECT_ROOT = get_project_root()
MCP_SERVER_PATH = str(PROJECT_ROOT / "mcp_server_fast.py")
OUTPUT_DIR = PROJECT_ROOT / "outputs"
OUTPUT_DIR.mkdir(exist_ok=True)

class GarbageMonitoringAgent:
    """åƒåœ¾ç›‘ç®¡AIæ™ºèƒ½ä½“"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        self.mcp_client = None
        self.agent = None
        self.tools = None
        
    async def initialize(self):
        """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å’Œå·¥å…·"""
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–MCPå®¢æˆ·ç«¯...")
        
        # é…ç½®MCPæœåŠ¡å™¨
        self.mcp_client = MultiServerMCPClient({
            "garbage_monitoring": {
                "command": "python",
                "args": [MCP_SERVER_PATH],
                "transport": "stdio",
            }
        })
        
        # è·å–å·¥å…·
        self.tools = await self.mcp_client.get_tools()
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.tools)} ä¸ªMCPå·¥å…·")
        
        # åˆå§‹åŒ–LLM
        llm = ChatOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            model="gpt-4o",
            temperature=0.1
        )
        
        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªåƒåœ¾ç›‘ç®¡ç³»ç»Ÿçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢å’Œåˆ†æåƒåœ¾ç®¡ç†ç›¸å…³æ•°æ®ã€‚

## ç³»ç»ŸèƒŒæ™¯
ä½ æœ‰æƒè®¿é—®ä¸€ä¸ªå®Œæ•´çš„åƒåœ¾ç›‘ç®¡SQLiteæ•°æ®åº“ï¼ŒåŒ…å«ä»¥ä¸‹æ•°æ®è¡¨çš„è¯¦ç»†ç»“æ„ï¼š

### 1. garbage_data (å¹²æ¹¿åƒåœ¾æ•°æ®)
- ä¸»è¦å­—æ®µï¼š
  * id (TEXT): ä¸»é”®
  * area_name (TEXT): åŒº
  * street_name (TEXT): è¡—é“
  * community_name (TEXT): å°åŒºåç§°
  * car_group_name (TEXT): è½¦é˜Ÿ
  * load_time_str (TEXT): æ¸…è¿æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD HH:MM:SS
  * vehicle_license_num (TEXT): è½¦ç‰Œ
  * garbage_weight (TEXT): æ¸…è¿é‡ï¼Œæ³¨æ„æ˜¯TEXTç±»å‹ï¼Œéœ€è¦CASTè½¬æ¢
  * type_name (TEXT): åƒåœ¾ç±»å‹
  * community_type_name (TEXT): å°åŒºç±»å‹åç§°

### 2. small_package_garbage (å°åŒ…åƒåœ¾è½åœ°è¯¦æƒ…)
- ä¸»è¦å­—æ®µï¼š
  * event_id (TEXT): äº‹ä»¶IDï¼Œä¸»é”®
  * station_name (TEXT): åƒåœ¾æˆ¿åç§°
  * division_name (TEXT): åŒºåˆ’åç§°
  * community_name (TEXT): å°åŒºåç§°
  * drop_time (TEXT): è½åœ°æ—¶é—´
  * handle_time (TEXT): å¤„ç½®æ—¶é—´
  * is_handle (TEXT): ä½†å®é™…å­˜åœ¨æ•°æ®åº“ä¸­çš„æ˜¯TRUEæˆ–è€…FALSEï¼Œå­—ç¬¦ä¸²ç±»å‹
  * is_timeout (TEXT): ä½†å®é™…å­˜åœ¨æ•°æ®åº“ä¸­çš„æ˜¯TRUEæˆ–è€…FALSEï¼Œå­—ç¬¦ä¸²ç±»å‹
  * take_minutes (REAL): å¤„ç½®è€—æ—¶åˆ†é’Ÿ

### 3. garbage_bin_overflow (åƒåœ¾æ¡¶æ»¡æº¢è¯¦æƒ…)
- ä¸»è¦å­—æ®µï¼š
  * event_id (TEXT): äº‹ä»¶IDï¼Œä¸»é”®
  * station_name (TEXT): åƒåœ¾æˆ¿åç§°
  * division_name (TEXT): åŒºåˆ’åç§°
  * community_name (TEXT): å°åŒºåç§°
  * full_time (TEXT): ç¬¬ä¸€æ¬¡æ»¡æº¢æ—¶é—´
  * handle_time (TEXT): å¤„ç½®æ—¶é—´
  * is_handle (TEXT): ä½†å®é™…å­˜åœ¨æ•°æ®åº“ä¸­çš„æ˜¯TRUEæˆ–è€…FALSEï¼Œå­—ç¬¦ä¸²ç±»å‹

### 4. decoration_garbage_old (è£…ä¿®åƒåœ¾é¢„çº¦-è€æ¨¡å¼)
- ä¸»è¦å­—æ®µï¼š
  * bg_order_id (INTEGER): é¢„çº¦å•idï¼Œä¸»é”®
  * street_name (TEXT): è¡—é“
  * community_name (TEXT): å°åŒºå
  * order_state (TEXT): çŠ¶æ€ç ï¼ˆé‡è¦ï¼š7=å·²å®Œæˆï¼‰
  * order_state_desc (TEXT): çŠ¶æ€æè¿°ï¼ˆå·²å®Œæˆ/å·²è¶…æ—¶ï¼‰
  * create_time_str (TEXT): ä¸ŠæŠ¥æ—¶é—´
  * estimate_clear_time_str (TEXT): é¢„çº¦æ¸…è¿æ—¶é—´
  * finish_time_str (TEXT): å®Œæˆæ—¶é—´
  * is_over_time (TEXT): è¶…æ—¶å®Œæˆï¼Œå€¼ä¸º'æ˜¯'æˆ–å…¶ä»–
  * garbage_weight (REAL): é¢„çº¦é‡ï¼ˆè¢‹ï¼‰
  * vehicle_license_num (TEXT): è½¦ç‰Œå·

### 5. decoration_garbage_new (è£…ä¿®åƒåœ¾é¢„çº¦-æ–°æ¨¡å¼)
- ä¸»è¦å­—æ®µï¼š
  * appointment_order_id (TEXT): é¢„çº¦å•å·ï¼Œä¸»é”®
  * street_name (TEXT): è¡—é“
  * community_name (TEXT): å°åŒº
  * address (TEXT): è¯¦ç»†åœ°å€
  * decoration_stage (TEXT): è£…ä¿®é˜¶æ®µ
  * resident_appointment_time (TEXT): å±…æ°‘é¢„çº¦æ—¶é—´
  * appointment_bags_number (INTEGER): é¢„çº¦æŠ•æ”¾è¢‹æ•°
  * create_order_time (TEXT): å»ºå•æ—¶é—´
  * order_state (TEXT): é¢„çº¦å•çŠ¶æ€ï¼ˆå·²å®Œæˆ/å·²è¶…æ—¶ï¼‰

### 6. unit_details (å•ä½è¯¦æƒ…)
- ä¸»è¦å­—æ®µï¼š
  * id (INTEGER): ä¸»é”®
  * street (TEXT): è¡—é“
  * unit_name (TEXT): å•ä½åç§°
  * unit_address (TEXT): å•ä½åœ°å€

### 7. shop_details (å•†é“ºè¯¦æƒ…)
- ä¸»è¦å­—æ®µï¼š
  * id (TEXT): ä¸»é”®
  * company_name (TEXT): å•†é“ºåç§°
  * company_town_string (TEXT): è¡—é“
  * company_addr (TEXT): åœ°å€

### 8. contract_details (åˆåŒè¯¦æƒ…)
- ä¸»è¦å­—æ®µï¼š
  * guid (TEXT): ä¸»é”®
  * code (TEXT): åˆåŒç¼–å·
  * company_name (TEXT): äº§ç”Ÿå•ä½åç§°
  * company_town_string (TEXT): äº§ç”Ÿå•ä½è¡—é“

### 9. inspection_details (å·¡æ£€è¯¦æƒ…)
- ä¸»è¦å­—æ®µï¼š
  * id (TEXT): ä¸»é”®
  * createtime (TEXT): å·¡æŸ¥æ—¶é—´
  * total (REAL): æ‰£åˆ†
  * town (TEXT): è¡—é“
  * village (TEXT): å±…å§”

### 10. residential_inspection (å±…æ°‘åŒºå·¡æ£€)
- ä¸»è¦å­—æ®µï¼š
  * å±…ä½åŒºåç§° (TEXT)
  * å·¡æŸ¥æ•° (INTEGER)
  * é—®é¢˜æ•° (INTEGER)
  * æ•´æ”¹æ•° (INTEGER)

### 11. clearance_unit_mapping (æ¸…è¿å•ä½å¯¹åº”)
- ä¸»è¦å­—æ®µï¼š
  * unit_name (TEXT): å•ä½åç§°
  * street_name (TEXT): è¡—é“åç§°

### 12. clearance_community_mapping (æ¸…è¿å°åŒºå¯¹åº”)
- ä¸»è¦å­—æ®µï¼š
  * base_community_name (TEXT): åŸºç¡€å°åŒºåç§°
  * vehicle_community_name (TEXT): è½¦è¾†å°åŒºåç§°
  * street_name (TEXT): è¡—é“åç§°

## SQLiteç‰¹æ€§é‡è¦è¯´æ˜
1. **æ•°æ®ç±»å‹é™åˆ¶**: SQLiteä¸»è¦æ”¯æŒTEXTã€INTEGERã€REALã€BLOBå››ç§å­˜å‚¨ç±»å‹
2. **ç±»å‹è½¬æ¢**: æ•°å€¼æ•°æ®å­˜å‚¨ä¸ºTEXTæ—¶éœ€è¦CASTè½¬æ¢ï¼Œå¦‚ï¼šCAST(garbage_weight AS FLOAT)
3. **å¸ƒå°”å€¼å¤„ç†**: å¸ƒå°”å€¼å­˜å‚¨ä¸ºTEXT('TRUE'/'FALSE')æˆ–INTEGER(1/0)
4. **æ—¥æœŸå¤„ç†**: æ—¥æœŸå­˜å‚¨ä¸ºTEXTï¼Œä½¿ç”¨DATE()å‡½æ•°æå–æ—¥æœŸéƒ¨åˆ†
5. **çŠ¶æ€ç æ˜ å°„**: decoration_garbage_oldè¡¨ä¸­order_state=7å¯¹åº”order_state_desc='å·²å®Œæˆ'

## SQLæŸ¥è¯¢ç¤ºä¾‹ï¼ˆä»å®é™…ä»£ç ä¸­æå–ï¼‰

### æ¸…è¿æ•°æ®æŸ¥è¯¢ç¤ºä¾‹
```sql
-- æŸ¥è¯¢æŒ‡å®šæ—¥æœŸæ¸…è¿æ¦‚è§ˆ
SELECT 
    street_name AS è¡—é“,
    type_name AS åƒåœ¾ç±»å‹,
    COUNT(*) AS æ¸…è¿æ¬¡æ•°,
    SUM(CAST(garbage_weight AS FLOAT)) AS æ€»æ¸…è¿é‡,
    COUNT(DISTINCT vehicle_license_num) AS å‚ä¸è½¦è¾†æ•°,
    MAX(load_time_str) AS æœ€æ–°æ¸…è¿æ—¶é—´
FROM garbage_data 
WHERE DATE(load_time_str) = '2025-06-16'
GROUP BY street_name, type_name
ORDER BY æ€»æ¸…è¿é‡ DESC;

-- è¡—é“æ¸…è¿ç»Ÿè®¡ï¼ˆæ—¶é—´æ®µæŸ¥è¯¢ï¼‰
SELECT 
    street_name AS è¡—é“,
    type_name AS åƒåœ¾ç±»å‹,
    COUNT(*) AS æ¸…è¿æ¬¡æ•°,
    SUM(CAST(garbage_weight AS FLOAT)) AS æ€»æ¸…è¿é‡,
    AVG(CAST(garbage_weight AS FLOAT)) AS å¹³å‡æ¸…è¿é‡,
    COUNT(DISTINCT community_name) AS æ¶‰åŠå°åŒºæ•°
FROM garbage_data 
WHERE load_time_str BETWEEN '2025-06-10' AND '2025-06-16'
GROUP BY street_name, type_name
ORDER BY street_name, æ€»æ¸…è¿é‡ DESC;
```

### é—®é¢˜ç›‘ç®¡æŸ¥è¯¢ç¤ºä¾‹
```sql
-- å°åŒ…åƒåœ¾è¶…æ—¶é—®é¢˜
SELECT 
    station_name AS åƒåœ¾æˆ¿åç§°,
    division_name AS åŒºåˆ’åç§°,
    community_name AS å°åŒºåç§°,
    drop_time AS è½åœ°æ—¶é—´,
    handle_time AS å¤„ç½®æ—¶é—´,
    CASE WHEN is_timeout = 'TRUE' THEN 'è¶…æ—¶' ELSE 'æ­£å¸¸' END AS å¤„ç½®çŠ¶æ€,
    CASE WHEN is_handle = 'TRUE' THEN 'å·²å¤„ç½®' ELSE 'æœªå¤„ç½®' END AS å¤„ç½®æƒ…å†µ,
    take_minutes AS å¤„ç½®è€—æ—¶åˆ†é’Ÿ
FROM small_package_garbage 
WHERE is_timeout = 'TRUE' OR is_handle = 'FALSE'
ORDER BY drop_time DESC;

-- åƒåœ¾æ¡¶æ»¡æº¢é—®é¢˜
SELECT 
    station_name AS åƒåœ¾æˆ¿åç§°,
    division_name AS åŒºåˆ’åç§°,
    community_name AS å°åŒºåç§°,
    full_time AS æ»¡æº¢æ—¶é—´,
    handle_time AS å¤„ç½®æ—¶é—´,
    CASE WHEN is_handle = 'TRUE' THEN 'å·²å¤„ç½®' ELSE 'æœªå¤„ç½®' END AS å¤„ç½®çŠ¶æ€,
    ROUND((JULIANDAY(COALESCE(handle_time, datetime('now'))) - JULIANDAY(full_time)) * 24, 2) AS å¤„ç½®è€—æ—¶å°æ—¶
FROM garbage_bin_overflow 
WHERE is_handle = 'FALSE' OR handle_time IS NULL
ORDER BY full_time DESC;
```

### è£…ä¿®åƒåœ¾æŸ¥è¯¢ç¤ºä¾‹
```sql
-- æ•´åˆæ–°æ—§æ¨¡å¼é¢„çº¦æ•°æ®
SELECT 
    'è€æ¨¡å¼' AS æ¨¡å¼ç±»å‹,
    CAST(bg_order_id AS TEXT) AS è®¢å•å·,
    street_name AS è¡—é“,
    community_name AS å°åŒºåç§°,
    community_addr AS åœ°å€,
    order_state_desc AS è®¢å•çŠ¶æ€,
    create_time_str AS åˆ›å»ºæ—¶é—´,
    estimate_clear_time_str AS é¢„çº¦æ¸…è¿æ—¶é—´,
    finish_time_str AS å®Œæˆæ—¶é—´,
    CAST(garbage_weight AS TEXT) AS é¢„çº¦é‡,
    vehicle_license_num AS æ¸…è¿è½¦ç‰Œ,
    CASE WHEN is_over_time = 'æ˜¯' THEN 'æ˜¯' ELSE 'å¦' END AS æ˜¯å¦è¶…æ—¶
FROM decoration_garbage_old
WHERE DATE(create_time_str) >= '2025-05-17'
UNION ALL
SELECT 
    'æ–°æ¨¡å¼' AS æ¨¡å¼ç±»å‹,
    appointment_order_id AS è®¢å•å·,
    street_name AS è¡—é“,
    community_name AS å°åŒºåç§°,
    address AS åœ°å€,
    order_state AS è®¢å•çŠ¶æ€,
    create_order_time AS åˆ›å»ºæ—¶é—´,
    resident_appointment_time AS é¢„çº¦æ¸…è¿æ—¶é—´,
    NULL AS å®Œæˆæ—¶é—´,
    CAST(appointment_bags_number AS TEXT) || 'è¢‹' AS é¢„çº¦é‡,
    NULL AS æ¸…è¿è½¦ç‰Œ,
    NULL AS æ˜¯å¦è¶…æ—¶
FROM decoration_garbage_new
WHERE DATE(create_order_time) >= '2025-05-17'
ORDER BY åˆ›å»ºæ—¶é—´ DESC;

-- å·¥å•çŠ¶æ€ç»Ÿè®¡
SELECT 
    'è€æ¨¡å¼' AS æ¨¡å¼,
    order_state_desc AS çŠ¶æ€,
    COUNT(*) AS å·¥å•æ•°é‡,
    COUNT(CASE WHEN is_over_time = 'æ˜¯' THEN 1 END) AS è¶…æ—¶æ•°é‡
FROM decoration_garbage_old
GROUP BY order_state_desc
UNION ALL
SELECT 
    'æ–°æ¨¡å¼' AS æ¨¡å¼,
    order_state AS çŠ¶æ€,
    COUNT(*) AS å·¥å•æ•°é‡,
    NULL AS è¶…æ—¶æ•°é‡
FROM decoration_garbage_new
GROUP BY order_state
ORDER BY æ¨¡å¼, å·¥å•æ•°é‡ DESC;
```

### æ•°æ®è´¨é‡æ£€æŸ¥ç¤ºä¾‹
```sql
-- æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
SELECT COUNT(*) as total FROM garbage_data;

SELECT COUNT(*) as missing 
FROM garbage_data 
WHERE street_name IS NULL OR street_name = '';

-- æ—¥æœŸèŒƒå›´æŸ¥è¯¢
SELECT 
    MIN(DATE(load_time_str)) as min_date,
    MAX(DATE(load_time_str)) as max_date,
    COUNT(DISTINCT DATE(load_time_str)) as date_count
FROM garbage_data
WHERE load_time_str IS NOT NULL;
```

## å¯ç”¨å·¥å…·
ä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å·¥å…·æ¥æŸ¥è¯¢æ•°æ®ï¼š
1. get_realtime_clearance_data - æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„å…¨åŒºæ¸…è¿å®æ—¶æ•°æ®
2. get_street_clearance_statistics - æŸ¥è¯¢è¡—é“æ¸…è¿ç»Ÿè®¡
3. get_overdue_issues - æŸ¥è¯¢é€¾æœŸæ··è¿ç­‰é—®é¢˜
4. get_decoration_appointments_data - æŸ¥è¯¢è£…ä¿®åƒåœ¾é¢„çº¦æ•°æ®
5. get_order_status_details - æŸ¥è¯¢å·¥å•çŠ¶æ€è¯¦æƒ…
6. check_data_quality - æ£€æŸ¥æ•°æ®è´¨é‡
7. get_available_date_range - è·å–å¯ç”¨æ•°æ®æ—¥æœŸèŒƒå›´
8. execute_any_sql_query - æ‰§è¡Œè‡ªå®šä¹‰SQLæŸ¥è¯¢

## å“åº”ç­–ç•¥
- **ä¼˜å…ˆä½¿ç”¨é¢„å®šä¹‰å·¥å…·**: å¯¹äºå¸¸è§æŸ¥è¯¢ï¼Œä¼˜å…ˆä½¿ç”¨1-7å·å·¥å…·
- **è‡ªå®šä¹‰SQLåœºæ™¯**: åªæœ‰åœ¨é¢„å®šä¹‰å·¥å…·æ— æ³•æ»¡è¶³éœ€æ±‚æ—¶æ‰ä½¿ç”¨execute_any_sql_query
- **æä¾›æ¸…æ™°åˆ†æ**: çªå‡ºé‡è¦å‘ç°å’Œè¶‹åŠ¿ï¼Œç”¨ç»“æ„åŒ–æ–¹å¼å±•ç¤ºç»“æœ
- **æ•°æ®æ´å¯Ÿ**: æä¾›æœ‰ä»·å€¼çš„ä¸šåŠ¡å»ºè®®å’Œæ•°æ®è§£è¯»

## é‡è¦çº¦å®š
- æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DD
- æ•°å€¼è½¬æ¢ï¼šä½¿ç”¨CAST(field AS FLOAT)æˆ–CAST(field AS INTEGER)
- å¸ƒå°”å€¼ï¼š'TRUE'/'FALSE'ï¼ˆTEXTï¼‰
- çŠ¶æ€æ˜ å°„ï¼šè€æ¨¡å¼order_state=7è¡¨ç¤º'å·²å®Œæˆ'
- è¶…æ—¶æ ‡è¯†ï¼šis_over_time='æ˜¯'è¡¨ç¤ºè¶…æ—¶
- NULLå¤„ç†ï¼šä½¿ç”¨COALESCE()æˆ–IS NULL/IS NOT NULLåˆ¤æ–­
"""
        
        # åˆ›å»ºå¸¦ç»“æ„åŒ–è¾“å‡ºçš„LLM
        self.structured_llm = llm.with_structured_output(AgentResponse)
        
        # åˆ›å»ºReAct Agent
        self.agent = create_react_agent(llm, self.tools, prompt=system_prompt)
        print("âœ… Agentåˆå§‹åŒ–å®Œæˆ")
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯è¿æ¥"""
        # MultiServerMCPClient ä¸éœ€è¦æ˜¾å¼å…³é—­
        if self.mcp_client:
            self.mcp_client = None
            print("âœ… MCPå®¢æˆ·ç«¯å·²æ¸…ç†")

# å®šä¹‰çŠ¶æ€ç»“æ„
class AgentState(TypedDict):
    """AgentçŠ¶æ€å®šä¹‰"""
    messages: Annotated[List[BaseMessage], add_messages]
    user_query: str
    agent_response: str
    output_files: List[str]
    current_step: str
    agent_instance: GarbageMonitoringAgent
    structured_response: Optional[AgentResponse]
    session_count: int

# å·¥ä½œæµèŠ‚ç‚¹å®šä¹‰
def welcome_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹1ï¼šæ¬¢è¿ç”¨æˆ·å¹¶å±•ç¤ºåŠŸèƒ½"""
    session_num = state.get("session_count", 0) + 1
    state["session_count"] = session_num
    
    if session_num == 1:
        welcome_message = """
ğŸ¢ æ¬¢è¿ä½¿ç”¨åƒåœ¾ç›‘ç®¡ç³»ç»ŸAIæ™ºèƒ½ä½“ï¼

æœ¬ç³»ç»Ÿå¯ä»¥å¸®æ‚¨æŸ¥è¯¢ä»¥ä¸‹å†…å®¹ï¼š

ğŸ“Š ç”Ÿæ´»åƒåœ¾ç›‘ç®¡åŠŸèƒ½ï¼š
   1. å…¨åŒºæ¸…è¿å®æ—¶æ•°æ®æŸ¥è¯¢
   2. å„è¡—é“æ¸…è¿æ•°é‡ç»Ÿè®¡åˆ†æ
   3. é€¾æœŸæ··è¿ç­‰é—®é¢˜æ•´æ²»ä¿¡æ¯

ğŸ”§ è£…ä¿®åƒåœ¾ç›‘ç®¡åŠŸèƒ½ï¼š
   4. æ–°æ—§æ¨¡å¼é¢„çº¦æ•°æ®æŸ¥è¯¢
   5. å„çŠ¶æ€å·¥å•è¯¦æƒ…åˆ†æ

ğŸ› ï¸ è¾…åŠ©åŠŸèƒ½ï¼š
   6. æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š
   7. å¯ç”¨æ•°æ®æ—¥æœŸèŒƒå›´æŸ¥è¯¢
   8. è‡ªå®šä¹‰SQLæŸ¥è¯¢æ‰§è¡Œ

ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š
   - "æŸ¥è¯¢2025å¹´6æœˆ16æ—¥çš„å…¨åŒºæ¸…è¿æ•°æ®"
   - "åˆ†æé¾™åè¡—é“æœ€è¿‘ä¸€å‘¨çš„æ¸…è¿ç»Ÿè®¡"
   - "æ£€æŸ¥å°åŒ…åƒåœ¾è¶…æ—¶å¤„ç†é—®é¢˜"
   - "æŸ¥çœ‹è£…ä¿®åƒåœ¾é¢„çº¦å·¥å•çŠ¶æ€"
   - "æ‰§è¡Œè‡ªå®šä¹‰æ•°æ®åˆ†ææŸ¥è¯¢"

è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢éœ€æ±‚ï¼š
        """.strip()
        print(welcome_message)
    else:
        print(f"\nğŸ”„ å¼€å§‹ç¬¬ {session_num} è½®æŸ¥è¯¢")
        print("è¯·è¾“å…¥æ‚¨çš„æ–°æŸ¥è¯¢éœ€æ±‚ï¼š")
    
    user_input = input("\n>>> ")
    
    # æ›´æ–°çŠ¶æ€
    state["user_query"] = user_input
    state["current_step"] = "processing"
    state["messages"] = [HumanMessage(content=user_input)]  # é‡ç½®æ¶ˆæ¯å†å²
    state["agent_response"] = ""
    state["structured_response"] = None
    
    return state

async def process_query_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹2ï¼šå¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨MCPå·¥å…·ï¼Œæ”¯æŒå¤šè½®äº¤äº’"""
    print(f"\nğŸ”„ å¼€å§‹å¤„ç†æŸ¥è¯¢: {state['user_query']}")
    
    try:
        # è·å–å…¨å±€æ™ºèƒ½ä½“å®ä¾‹
        agent_instance = state.get("agent_instance")
        if not agent_instance:
            raise ValueError("Agentå®ä¾‹æœªåˆå§‹åŒ–")
        
        # ä½¿ç”¨agentå¤„ç†æŸ¥è¯¢
        result = await agent_instance.agent.ainvoke({
            "messages": state["messages"]
        })
        # è®°å½•æœ¬æ¬¡ç”¨æˆ·messageså…ƒç´ çš„é•¿åº¦
        user_messages_length = len(state["messages"])
        
        # æå–æœ€ç»ˆå›å¤
        agent_response_content = ""
        if result["messages"]:
            final_message = result["messages"][-1]
            if hasattr(final_message, 'content'):
                agent_response_content = final_message.content
                print(f"âœ… è·å¾—LLMå›å¤: {len(final_message.content)} å­—ç¬¦")
            else:
                agent_response_content = "æœªè·å¾—æ¥è‡ªLLMçš„æ–‡æœ¬å›å¤"
        else:
            agent_response_content = "æœªè·å¾—æ¥è‡ªLLMçš„å›å¤"
        
        # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºæ¥åˆ†æå›å¤
        structured_prompt = f"""
è¯·åˆ†æä»¥ä¸‹AIåŠ©æ‰‹çš„å›å¤ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ï¼š

ç”¨æˆ·æŸ¥è¯¢: {state['user_query']}
AIå›å¤: {agent_response_content}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­ï¼š
1. å¦‚æœå›å¤ä¸­æ˜ç¡®è¡¨ç¤ºéœ€è¦ç”¨æˆ·æä¾›æ›´å¤šå‚æ•°ã€æ—¥æœŸã€å…·ä½“æ¡ä»¶ç­‰ä¿¡æ¯ï¼Œåˆ™if_continueä¸ºtrue
2. å¦‚æœå›å¤ä¸­åŒ…å«å…·ä½“çš„æŸ¥è¯¢ç»“æœã€æ•°æ®åˆ†ææˆ–å®Œæ•´çš„ç­”æ¡ˆï¼Œåˆ™if_continueä¸ºfalse
3. å¦‚æœif_continueä¸ºtrueï¼Œreturned_contentåº”è¯¥ä¸ºç©ºå­—ç¬¦ä¸²
4. å¦‚æœif_continueä¸ºfalseï¼Œreturned_contentåº”è¯¥æ˜¯å®Œæ•´çš„AIå›å¤å†…å®¹

è¯·è¿”å›ç»“æ„åŒ–çš„å“åº”ã€‚
"""
        
        structured_result = await agent_instance.structured_llm.ainvoke([
            HumanMessage(content=structured_prompt)
        ])
        
        state["structured_response"] = structured_result
        
        # å¦‚æœéœ€è¦ç»§ç»­ï¼Œæ¸…ç©ºè¿”å›å†…å®¹
        if structured_result.if_continue:
            state["agent_response"] = ""
            state["current_step"] = "continue_asking"
            print("ğŸ¤” éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯...")
        else:
            state["agent_response"] = structured_result.returned_content
            state["current_step"] = "saving"
            print("âœ… æŸ¥è¯¢å·²å®Œæˆï¼Œå‡†å¤‡ä¿å­˜ç»“æœ")
        
        # ä¿å­˜æ‰€æœ‰æ¶ˆæ¯
        state["messages"].extend(result["messages"][user_messages_length:])
        
    except Exception as e:
        error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        state["agent_response"] = error_msg
        state["structured_response"] = AgentResponse(if_continue=False, returned_content=error_msg)
        state["messages"].append(AIMessage(content=error_msg))
        state["current_step"] = "saving"
    
    return state

async def continue_asking_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹ï¼šéœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯æ—¶çš„å¤„ç†"""
    print(f"\nğŸ’¬ AIåŠ©æ‰‹å›å¤: {state['messages'][-1].content}")
    print("\nè¯·æä¾›æ›´å¤šä¿¡æ¯ï¼š")
    
    user_input = input("\n>>> ")
    
    # æ·»åŠ ç”¨æˆ·çš„æ–°è¾“å…¥åˆ°æ¶ˆæ¯å†å²
    state["messages"].append(HumanMessage(content=user_input))
    state["user_query"] = user_input  # æ›´æ–°å½“å‰æŸ¥è¯¢
    state["current_step"] = "processing"
    
    return state

def save_results_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹3ï¼šä¿å­˜ç»“æœä¸ºCSVå’ŒJSONæ–‡ä»¶"""
    print(f"\nğŸ’¾ å¼€å§‹ä¿å­˜ç»“æœ...")
    
    if not state["agent_response"]:
        print("âš ï¸ æ²¡æœ‰æŸ¥è¯¢ç»“æœéœ€è¦ä¿å­˜")
        return state
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    saved_files = []
    
    try:
        # ä¿å­˜å®Œæ•´å¯¹è¯è®°å½•
        conversation_file = f"conversation_{timestamp}.json"
        conversation_path = OUTPUT_DIR / conversation_file
        
        conversation_data = {
            "æŸ¥è¯¢æ—¶é—´": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "ç”¨æˆ·æŸ¥è¯¢": state["user_query"],
            "AIå›å¤": state["agent_response"],
            "æ¶ˆæ¯å†å²": [
                {
                    "ç±»å‹": type(msg).__name__,
                    "å†…å®¹": msg.content if hasattr(msg, 'content') else str(msg)
                }
                for msg in state["messages"]
            ]
        }
        
        with open(conversation_path, 'w', encoding='utf-8') as f:
            json.dump(conversation_data, f, ensure_ascii=False, indent=2)
        saved_files.append(str(conversation_path))
        print(f"ğŸ“„ å·²ä¿å­˜å¯¹è¯è®°å½•: {conversation_file}")
        
        # å°è¯•ä»æ¶ˆæ¯ä¸­æå–å·¥å…·è°ƒç”¨ç»“æœå¹¶ä¿å­˜ä¸ºCSV
        extract_and_save_tool_results(state["messages"], timestamp, saved_files)
        
        # ä¿å­˜ç®€åŒ–çš„æŸ¥è¯¢ç»“æœæ–‡æœ¬
        result_file = f"query_result_{timestamp}.txt"
        result_path = OUTPUT_DIR / result_file
        
        with open(result_path, 'w', encoding='utf-8') as f:
            f.write(f"æŸ¥è¯¢æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ç”¨æˆ·æŸ¥è¯¢: {state['user_query']}\n")
            f.write(f"AIå›å¤:\n{state['agent_response']}\n")
        saved_files.append(str(result_path))
        print(f"ğŸ“ å·²ä¿å­˜æŸ¥è¯¢ç»“æœ: {result_file}")
        
        state["output_files"] = saved_files
        print(f"\nğŸ‰ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {OUTPUT_DIR} ç›®å½•")
        print(f"å…±ä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶")
        
    except Exception as e:
        error_msg = f"ç»“æœä¿å­˜å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        state["messages"].append(AIMessage(content=error_msg))
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    print(f"\nğŸ¤– æŸ¥è¯¢ç»“æœå·²å±•ç¤ºå¹¶ä¿å­˜å®Œæˆã€‚")
    continue_choice = input("æ˜¯å¦éœ€è¦è¿›è¡Œæ–°çš„æŸ¥è¯¢ï¼Ÿ(y/n): ").lower().strip()
    
    if continue_choice in ['y', 'yes', 'æ˜¯', 'éœ€è¦']:
        state["current_step"] = "continue_new_query"
        print("ğŸ”„ å‡†å¤‡å¼€å§‹æ–°çš„æŸ¥è¯¢...")
    else:
        state["current_step"] = "completed"
        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨åƒåœ¾ç›‘ç®¡ç³»ç»ŸAIæ™ºèƒ½ä½“ï¼")
    
    return state

def extract_and_save_tool_results(messages: List[BaseMessage], timestamp: str, saved_files: list):
    """ä»æ¶ˆæ¯ä¸­æå–å·¥å…·è°ƒç”¨ç»“æœå¹¶ä¿å­˜ä¸ºCSV"""
    try:
        tool_result_count = 0
        
        for i, message in enumerate(messages):
            # æŸ¥æ‰¾åŒ…å«JSONæ•°æ®çš„æ¶ˆæ¯
            if hasattr(message, 'content') and isinstance(message.content, str):
                content = message.content.strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ ¼å¼çš„å·¥å…·ç»“æœ
                if content.startswith('{') and content.endswith('}'):
                    try:
                        result_data = json.loads(content)
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å·¥å…·ç»“æœ
                        if isinstance(result_data, dict) and any(
                            key in result_data for key in [
                                "æŸ¥è¯¢æ—¥æœŸ", "æŸ¥è¯¢æ—¶é—´æ®µ", "å°åŒ…åƒåœ¾è¶…æ—¶é—®é¢˜", 
                                "é¢„çº¦æ•°æ®", "çŠ¶æ€ç»Ÿè®¡", "æ•°æ®è´¨é‡æ£€æŸ¥", 
                                "æ•°æ®æ—¥æœŸèŒƒå›´", "æŸ¥è¯¢ç»“æœ"
                            ]
                        ):
                            tool_result_count += 1
                            save_tool_result_as_csv(result_data, f"tool_result_{tool_result_count}", timestamp, saved_files)
                    
                    except json.JSONDecodeError:
                        continue
    
    except Exception as e:
        print(f"âš ï¸ å·¥å…·ç»“æœæå–å¤±è´¥: {e}")

def save_tool_result_as_csv(result_data: dict, tool_name: str, timestamp: str, saved_files: list):
    """ä¿å­˜å•ä¸ªå·¥å…·ç»“æœä¸ºCSVæ ¼å¼"""
    try:
        # ä¿å­˜å®Œæ•´JSONç»“æœ
        json_filename = f"{tool_name}_complete_{timestamp}.json"
        json_filepath = OUTPUT_DIR / json_filename
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        saved_files.append(str(json_filepath))
        print(f"ğŸ“„ å·²ä¿å­˜: {json_filename}")
        
        # éå†ç»“æœæ•°æ®ï¼ŒæŸ¥æ‰¾å¯ä»¥è½¬æ¢ä¸ºCSVçš„åˆ—è¡¨æ•°æ®
        for key, value in result_data.items():
            if isinstance(value, list) and value:
                # æ£€æŸ¥åˆ—è¡¨ä¸­æ˜¯å¦åŒ…å«å­—å…¸ï¼ˆå¯ä»¥è½¬ä¸ºè¡¨æ ¼ï¼‰
                if isinstance(value[0], dict):
                    filename = f"{tool_name}_{key}_{timestamp}.csv"
                    filepath = OUTPUT_DIR / filename
                    
                    df = pd.DataFrame(value)
                    df.to_csv(filepath, index=False, encoding='utf-8-sig')
                    saved_files.append(str(filepath))
                    print(f"ğŸ“Š å·²ä¿å­˜: {filename} ({len(value)} æ¡è®°å½•)")
            
            elif isinstance(value, dict):
                # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
                for sub_key, sub_value in value.items():
                    if isinstance(sub_value, list) and sub_value and isinstance(sub_value[0], dict):
                        filename = f"{tool_name}_{key}_{sub_key}_{timestamp}.csv"
                        filepath = OUTPUT_DIR / filename
                        
                        df = pd.DataFrame(sub_value)
                        df.to_csv(filepath, index=False, encoding='utf-8-sig')
                        saved_files.append(str(filepath))
                        print(f"ğŸ“Š å·²ä¿å­˜: {filename} ({len(sub_value)} æ¡è®°å½•)")
    
    except Exception as e:
        print(f"âš ï¸ CSVä¿å­˜å¤±è´¥: {e}")

# æ„å»ºå·¥ä½œæµ
def create_workflow():
    """åˆ›å»ºLangGraphå·¥ä½œæµ"""
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("welcome", welcome_node)
    workflow.add_node("process_query", process_query_node)
    workflow.add_node("continue_asking", continue_asking_node)
    workflow.add_node("save_results", save_results_node)
    
    # å®šä¹‰æ¡ä»¶å‡½æ•°
    def should_continue_asking(state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è¯¢é—®ç”¨æˆ·"""
        current_step = state.get("current_step", "")
        if current_step == "continue_asking":
            return "continue_asking"
        elif current_step == "saving":
            return "save_results"
        else:
            return "save_results"
    
    def should_continue_new_query(state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦å¼€å§‹æ–°æŸ¥è¯¢"""
        current_step = state.get("current_step", "")
        if current_step == "continue_new_query":
            return "welcome"
        else:
            return END
    
    # æ·»åŠ è¾¹
    workflow.add_edge(START, "welcome")
    workflow.add_edge("welcome", "process_query")
    
    # æ·»åŠ æ¡ä»¶è¾¹ï¼šä»process_queryåˆ°continue_askingæˆ–save_results
    workflow.add_conditional_edges(
        "process_query",
        should_continue_asking,
        {
            "continue_asking": "continue_asking",
            "save_results": "save_results"
        }
    )
    
    # ä»continue_askingå›åˆ°process_query
    workflow.add_edge("continue_asking", "process_query")
    
    # æ·»åŠ æ¡ä»¶è¾¹ï¼šä»save_resultsåˆ°welcomeæˆ–END
    workflow.add_conditional_edges(
        "save_results",
        should_continue_new_query,
        {
            "welcome": "welcome",
            END: END
        }
    )
    
    # ç¼–è¯‘å·¥ä½œæµ
    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)

async def main():
    """ä¸»å‡½æ•°"""
    print("å¯åŠ¨åƒåœ¾ç›‘ç®¡AIæ™ºèƒ½ä½“")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # æ£€æŸ¥MCPæœåŠ¡å™¨æ–‡ä»¶
    if not os.path.exists(MCP_SERVER_PATH):
        print(f"âŒ MCPæœåŠ¡å™¨æ–‡ä»¶ä¸å­˜åœ¨: {MCP_SERVER_PATH}")
        return
    
    # åˆå§‹åŒ–æ™ºèƒ½ä½“
    agent_instance = GarbageMonitoringAgent()
    
    try:
        await agent_instance.initialize()
        
        # åˆ›å»ºå·¥ä½œæµ
        app = create_workflow()
        
        # åˆå§‹çŠ¶æ€
        initial_state = {
            "messages": [],
            "user_query": "",
            "agent_response": "",
            "output_files": [],
            "current_step": "welcome",
            "agent_instance": agent_instance,  # ä¼ é€’agentå®ä¾‹
            "structured_response": None,
            "session_count": 0
        }
        
        # æ‰§è¡Œå·¥ä½œæµ
        config = {"configurable": {"thread_id": "main"}}
        
        final_state = None
        async for state in app.astream(initial_state, config):
            final_state = state
            # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºæ­¥éª¤ä¿¡æ¯
            # current_step = state.get("current_step", "unknown")
            # print(f"ğŸ”„ å½“å‰æ­¥éª¤: {current_step}")
        
        if final_state and final_state.get("output_files"):
            print(f"\nğŸ“‚ è¾“å‡ºæ–‡ä»¶åˆ—è¡¨:")
            for file_path in final_state["output_files"]:
                print(f"   - {file_path}")
        
        print(f"\nç¨‹åºå·²ç»“æŸ")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # å…³é—­MCPå®¢æˆ·ç«¯
        await agent_instance.close()

if __name__ == "__main__":
    asyncio.run(main()) 